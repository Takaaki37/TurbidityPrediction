{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1685584955825,
     "user": {
      "displayName": "Takaaki Ishii",
      "userId": "10147196884984815882"
     },
     "user_tz": -540
    },
    "id": "Z2oqODEnHStq"
   },
   "outputs": [],
   "source": [
    "# 二値分類の場合は'binary、'多クラス分類の場合は'categorical'、回帰の場合は'raw'\n",
    "mode = \"binary\"\n",
    "\n",
    "# 教師データが含まれる列の名前\n",
    "class_label = \"class\"\n",
    "\n",
    "# 画像のサイズ\n",
    "img_size = 100\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 16\n",
    "\n",
    "# 使用するワーカーの数（PCによって異なる）\n",
    "worker = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリを読み込む\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# TensorFlowとKeras関連のインポート\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, model_from_json,\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.activations import softmax, relu\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# sklearnから評価指標をインポート\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1685584955825,
     "user": {
      "displayName": "Takaaki Ishii",
      "userId": "10147196884984815882"
     },
     "user_tz": -540
    },
    "id": "UBOYcOIX4WvA"
   },
   "outputs": [],
   "source": [
    "# csvの読み込み\n",
    "class dataLoad():\n",
    "    def __init__(self, train_csv_path, val_csv_path, test_csv_path, class_label=\"class2\"):\n",
    "        self.train_csv_path = train_csv_path\n",
    "        self.val_csv_path = val_csv_path\n",
    "        self.test_csv_path = test_csv_path\n",
    "        self.class_label = class_label\n",
    "\n",
    "    def setup(self):\n",
    "        df_train = pd.read_csv(self.train_csv_path)\n",
    "        df_val = pd.read_csv(self.val_csv_path)\n",
    "        df_test = pd.read_csv(self.test_csv_path)\n",
    "        return df_train, df_val, df_test\n",
    "\n",
    "DL = dataLoad('csv/traincsv', \n",
    "              'csv/val.csv', \n",
    "              'csv/test.csv', \n",
    "              class_label=class_label)\n",
    "\n",
    "train, val, test = DL.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の削除\n",
    "def cl_str(train, val, test):\n",
    "    train = train.dropna()\n",
    "    val = val.dropna()\n",
    "    test = test.dropna()\n",
    "    return train, val, test\n",
    "\n",
    "train, val, test = cl_str(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1685585217826,
     "user": {
      "displayName": "Takaaki Ishii",
      "userId": "10147196884984815882"
     },
     "user_tz": -540
    },
    "id": "0IHdweeq4Wzu"
   },
   "outputs": [],
   "source": [
    "# csvを使用して、画像を読み込みます。\n",
    "\n",
    "class generateGen():\n",
    "    def __init__(self, train_csv, val_csv, test_csv,\n",
    "                 train_img_path, val_img_path, test_img_path,\n",
    "                 img_size=200, batch_size=64, class_label=\"class2\", mode=\"binary\"):\n",
    "        self.train_csv = train_csv\n",
    "        self.val_csv = val_csv\n",
    "        self.test_csv = test_csv\n",
    "        self.train_img_path = train_img_path\n",
    "        self.val_img_path = val_img_path\n",
    "        self.test_img_path = test_img_path\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.class_label = class_label\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "    def datagen(self, df, path):\n",
    "        df.img_path = df.img_path.apply(lambda x: x)\n",
    "\n",
    "        if self.mode==\"binary\":\n",
    "            df[self.class_label] = df[self.class_label].astype('str')\n",
    "        elif self.mode == \"categorical\":\n",
    "            df[self.class_label] = df[self.class_label].astype('str')\n",
    "\n",
    "        datagen = image.ImageDataGenerator(rescale=1./255,\n",
    "                                        #    horizontal_flip=True,\n",
    "                                        #    vertical_flip=True,\n",
    "                                        #    rotation_range=360,\n",
    "                                        #    preprocessing_function=preprocess_image,\n",
    "                                           )\n",
    "\n",
    "\n",
    "        generator=datagen.flow_from_dataframe(dataframe=df,\n",
    "                                              directory=path,\n",
    "                                              x_col=\"img_path\",\n",
    "                                              y_col= self.class_label,\n",
    "                                              batch_size=self.batch_size,\n",
    "                                              class_mode=self.mode,\n",
    "                                              target_size=(self.img_size, self.img_size),\n",
    "                                              shuffle=False,\n",
    "                                              seed=2525,\n",
    "                                             )\n",
    "\n",
    "\n",
    "        NUB_STEPS=generator.n//generator.batch_size\n",
    "\n",
    "        return generator, NUB_STEPS\n",
    "\n",
    "    def test_datagen(self, df, path):\n",
    "        df.img_path = df.img_path.apply(lambda x: x)\n",
    "        if self.mode == \"binary\":\n",
    "            df[self.class_label] = df[self.class_label].astype('str')\n",
    "        elif self.mode == \"categorical\":\n",
    "            df[self.class_label] = df[self.class_label].astype('str')\n",
    "\n",
    "        datagen = image.ImageDataGenerator(rescale=1./255,\n",
    "                                           # horizontal_flip=True,\n",
    "                                           # vertical_flip=True,\n",
    "                                           # rotation_range=360,\n",
    "                                        #    preprocessing_function=preprocess_image,\n",
    "                                           )\n",
    "\n",
    "        test_generator = datagen.flow_from_dataframe(dataframe=df,\n",
    "                                                directory=path,\n",
    "                                                x_col=\"img_path\",\n",
    "                                                y_col=self.class_label,\n",
    "                                                batch_size=self.batch_size,\n",
    "                                                class_mode=self.mode,\n",
    "                                                target_size=(self.img_size, self.img_size),\n",
    "                                                shuffle=False,\n",
    "                                                seed=2525,\n",
    "                                                )\n",
    "\n",
    "        testNUB_STEPS = test_generator.n // test_generator.batch_size\n",
    "\n",
    "        return test_generator, testNUB_STEPS\n",
    "\n",
    "    def setup(self):\n",
    "        train_generator, train_steps = self.datagen(self.train_csv, self.train_img_path)\n",
    "        val_generator, val_steps = self.datagen(self.val_csv, self.val_img_path)\n",
    "        test_generator, test_steps = self.test_datagen(self.test_csv, self.test_img_path)\n",
    "\n",
    "        return  train_generator, train_steps, val_generator, val_steps, test_generator, test_steps\n",
    "\n",
    "gen = generateGen(train , val, test,\n",
    "                  train_img_path,\n",
    "                  val_img_path,\n",
    "                  test_img_path,\n",
    "                  img_size=img_size, \n",
    "                  batch_size=batch_size, \n",
    "                  class_label=class_label,\n",
    "                  mode=mode)\n",
    "\n",
    "\n",
    "train_generator, train_steps, val_generator, val_steps, test_generator, test_steps = gen.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1685585231804,
     "user": {
      "displayName": "Takaaki Ishii",
      "userId": "10147196884984815882"
     },
     "user_tz": -540
    },
    "id": "Nouke25Vak5Q"
   },
   "outputs": [],
   "source": [
    "# モデルの構築\n",
    "\n",
    "class CreateModel():\n",
    "    def __init__(self, n_out, img_dim=200, mode=\"class\"):\n",
    "        self.n_out = n_out\n",
    "        self.img_dim = img_dim\n",
    "        self.mode = mode\n",
    "\n",
    "    def setParametor(self):\n",
    "        if self.mode == \"binary\":\n",
    "            activation = 'sigmoid'\n",
    "            loss_function = keras.losses.binary_crossentropy\n",
    "            metrics = \"accuracy\"\n",
    "        elif self.mode == \"categorical\":\n",
    "            activation = 'softmax'\n",
    "            loss_function = keras.losses.categorical_crossentropy\n",
    "            metrics = \"accuracy\"\n",
    "        elif self.mode == \"raw\":\n",
    "            activation = \"linear\"\n",
    "            loss_function = keras.losses.mean_squared_error\n",
    "            metrics = \"mae\"\n",
    "        else:\n",
    "            print(\"modeが間違っています。\")\n",
    "        return activation, loss_function, metrics\n",
    "\n",
    "    def resnet50(self):\n",
    "        activation, loss_function, metrics = self.setParametor()\n",
    "        input_tensor = Input(shape=(self.img_dim, self.img_dim, 3))\n",
    "\n",
    "        base_model = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "        x = GlobalAveragePooling2D()(base_model.output)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(512, activation=relu)(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(128, activation=relu)(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        output_layer = Dense(self.n_out, activation=activation, name=\"Output_Layer\")(x)\n",
    "        model = Model(input_tensor, output_layer)\n",
    "\n",
    "        for layers in model.layers:\n",
    "            layers.trainable = True\n",
    "\n",
    "        lr = 0.01\n",
    "        optimizer=Adam(lr=lr)\n",
    "        model.compile(optimizer=optimizer, loss=loss_function,  metrics=[metrics])\n",
    "        return model\n",
    "      \n",
    "    def MCresnet50(self):\n",
    "        activation, loss_function, metrics = self.setParametor()\n",
    "        input_tensor = Input(shape=(self.img_dim, self.img_dim, 3))\n",
    "\n",
    "        base_model = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "        x = GlobalAveragePooling2D()(base_model.output)\n",
    "        x = Dropout(0.5)(x, training=True)\n",
    "        x = Dense(512, activation=relu)(x)\n",
    "        x = Dropout(0.5)(x, training=True)\n",
    "        x = Dense(128, activation=relu)(x)\n",
    "        x = Dropout(0.5)(x, training=True)\n",
    "        x = BatchNormalization()(x)\n",
    "        output_layer = Dense(self.n_out, activation=activation, name=\"Output_Layer\")(x)\n",
    "        model = Model(input_tensor, output_layer)\n",
    "\n",
    "        for layers in model.layers:\n",
    "            layers.trainable = True\n",
    "\n",
    "        lr = 0.001\n",
    "        optimizer=Adam(lr=lr)\n",
    "        model.compile(optimizer=optimizer, loss=loss_function,  metrics=[metrics])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg16(self):\n",
    "        activation, loss_function, metrics = self.setParametor()\n",
    "\n",
    "        input_tensor = Input(shape=(self.img_dim, self.img_dim, 3))\n",
    "        base_model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "        x = GlobalAveragePooling2D()(base_model.output)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(512, activation=relu)(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(128, activation=relu)(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        output_layer = Dense(self.n_out, activation=activation, name=\"Output_Layer\")(x)\n",
    "        model = Model(input_tensor, output_layer)\n",
    "\n",
    "        for layers in model.layers:\n",
    "            layers.trainable = True\n",
    "\n",
    "        lr = 0.001\n",
    "        optimizer=Adam(lr=lr,decay=0.1)\n",
    "        model.compile(optimizer=optimizer, loss=loss_function,  metrics=[metrics])\n",
    "        return model\n",
    "\n",
    "ml = CreateModel(n_out=1, img_dim=img_size, mode=mode)\n",
    "model = ml.MCresnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZudeDuE4W_b",
    "outputId": "8ba4c7a2-0e3d-4cba-8484-5f886a8555f5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 訓練開始\n",
    "epoch = 2\n",
    "\n",
    "dt_now = datetime.datetime.now()\n",
    "new_folder = str(dt_now.year) + str(dt_now.month) + str(dt_now.day)\n",
    "if not os.path.exists(new_folder):\n",
    "    os.mkdir(new_folder)\n",
    "\n",
    "ES = EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0.0001,\n",
    "                            patience=3,\n",
    "                            verbose=1,\n",
    "                            mode='auto')\n",
    "\n",
    "reduce_lr  = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                min_delta=0.0004,\n",
    "                                patience=2,\n",
    "                                factor=0.1,\n",
    "                                min_lr=1e-6,\n",
    "                                mode='auto',\n",
    "                                verbose=1)\n",
    "\n",
    "modelCheckpoint = ModelCheckpoint(filepath=new_folder + '/model_{epoch:02d}.h5',\n",
    "                                  monitor='val_loss',\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  save_weights_only=False,\n",
    "                                  )\n",
    "\n",
    "history = model.fit(x=train_generator,\n",
    "                    steps_per_epoch=train_steps,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=epoch,\n",
    "                    callbacks=[reduce_lr, modelCheckpoint, ES],\n",
    "                    verbose=1,\n",
    "                    workers=worker,\n",
    "                    )\n",
    "\n",
    "A = pd.DataFrame(history.history)\n",
    "A.to_csv(new_folder + '/acc_loss.csv')\n",
    "\n",
    "open(new_folder + '/model.json', \"w\").write(model.to_json())\n",
    "model.save_weights(new_folder + \"/model.h5\")\n",
    "\n",
    "if mode == \"binary\":\n",
    "    acc=history.history['accuracy']\n",
    "    val_acc=history.history['val_accuracy']\n",
    "\n",
    "    plt.plot(acc,label=\"Accuracy\")\n",
    "    plt.plot(val_acc)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(['Acc','val_acc'])\n",
    "    plt.plot( np.argmax(history.history[\"val_accuracy\"]), np.max(history.history[\"val_accuracy\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot( np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"log_loss\")\n",
    "    plt.savefig(new_folder + \"/loss.png\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "elif mode == \"categorical\":\n",
    "    acc=history.history['accuracy']\n",
    "    val_acc=history.history['val_accuracy']\n",
    "\n",
    "    plt.plot(acc,label=\"Accuracy\")\n",
    "    plt.plot(val_acc)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(['Acc','val_accuracy'])\n",
    "    plt.plot( np.argmax(history.history[\"val_accuracy\"]), np.max(history.history[\"val_accuracy\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.savefig(new_folder + \"/acc.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot( np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"log_loss\")\n",
    "    plt.savefig(new_folder + \"/loss.png\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "elif mode == \"raw\":\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot( np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"log_loss\")\n",
    "    plt.savefig(new_folder + \"/loss.png\")\n",
    "    plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8578,
     "status": "ok",
     "timestamp": 1685592148642,
     "user": {
      "displayName": "Takaaki Ishii",
      "userId": "10147196884984815882"
     },
     "user_tz": -540
    },
    "id": "R7Aro7Tq1mg5",
    "outputId": "7f9b0ffb-7e02-4bee-87ba-f84b499553bf"
   },
   "outputs": [],
   "source": [
    "path = './モデル'\n",
    "model_path = 'model.h5'\n",
    "\n",
    "json_file = open(path + \"/model.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "model.load_weights(path + '/' + model_path)\n",
    "\n",
    "if mode == \"binary\":\n",
    "    activation = 'sigmoid'\n",
    "    loss_function = tf.keras.losses.binary_crossentropy\n",
    "    metrics = \"accuracy\"\n",
    "elif mode == \"categorical\":\n",
    "    activation = 'softmax'\n",
    "    loss_function = tf.keras.losses.categorical_crossentropy\n",
    "    metrics = \"accuracy\"\n",
    "elif mode == \"raw\":\n",
    "    activation = \"linear\"\n",
    "    loss_function = tf.keras.losses.mean_squared_error\n",
    "    metrics = \"mae\"\n",
    "else:\n",
    "    print(\"modeが間違っています。\")\n",
    "\n",
    "\n",
    "lr = 0.0005\n",
    "optimizer=Adam(lr=lr)\n",
    "model.compile(optimizer=optimizer, loss=loss_function,  metrics=[metrics])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GennhFlmjG5j"
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = model.predict(x=test_generator, \n",
    "                          workers=worker)\n",
    "\n",
    "\n",
    "\n",
    "pred2 = [np.argmax(pred) for pred in preds]\n",
    "result = pd.DataFrame(columns = ['img_path', 'true', 'pred', 'pred5'])\n",
    "test = test.dropna()\n",
    "result['img_path'] = test[\"img_path\"]\n",
    "result['true'] = test['class'].astype('float').astype('int')\n",
    "result['pred'] = preds\n",
    "result['pred2'] = pred2\n",
    "\n",
    "\n",
    "result.to_csv(path + '/test_result.csv')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(result[\"true\"], result[\"pred2\"])\n",
    "print(cm)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.set(font_scale=1.4)\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\"d\", square=True)\n",
    "ax.set_xlabel(\"predict\")\n",
    "ax.set_ylabel(\"true\")\n",
    "ax.set_ylim(2.0, 0)\n",
    "plt.savefig(path + \"/test_cm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "for i in tqdm(range(10)):\n",
    "    pred = tqdm(model.predict(x=test_generator, steps=test_steps, workers=worker))\n",
    "    y_label = pd.DataFrame(test['img_path'])\n",
    "    y2 = pd.DataFrame(test[class_label])\n",
    "    y2[class_label] = y2[class_label].astype('float').astype('int')\n",
    "    pred2 = pd.DataFrame(pred)\n",
    "    pred3 = round(pred2)\n",
    "    pred3.columns = ['pred2']\n",
    "    pred3['pred2'] = pred3['pred2'].astype('int')\n",
    "    result = pd.concat([y_label, y2, pred2, pred3], axis=1)\n",
    "    result.columns = ['Label', 'true', 'pred', 'pred2']\n",
    "    result.to_csv(path + '/test_result_' + str(i) + '.csv')\n",
    "    a = result.query('true == pred2')\n",
    "    print('No', i)\n",
    "    print((len(a) / len(result) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "raw\n",
    "'''\n",
    "\n",
    "preds = model.predict(x=test_generator, workers=worker)\n",
    "prob = pd.DataFrame(preds, columns=['predict'])\n",
    "prob = prob.reset_index(drop=True)\n",
    "\n",
    "y_label = pd.DataFrame(test['img_path'])\n",
    "y_label = y_label.reset_index(drop=True)\n",
    "y2 = pd.DataFrame(test[class_label])\n",
    "y2 = y2.reset_index(drop=True)\n",
    "\n",
    "result = pd.concat([y_label, y2, prob], axis=1)\n",
    "result.columns = ['Label', 'true', 'pred']\n",
    "\n",
    "result.to_csv(path + '/test_result.csv', index=False)\n",
    "\n",
    "plt.scatter(result['true'], result['pred'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel(\"true\")\n",
    "plt.ylabel(\"predict\")\n",
    "plt.xlim(0, 50)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(path + '/test_regression.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('RMSE テスト: %.2f' %(\n",
    "    mean_squared_error(result['true'], result['pred'])\n",
    "))\n",
    "\n",
    "print('R^2 テスト: %.2f' %(\n",
    "    r2_score(result['true'], result['pred'])\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
